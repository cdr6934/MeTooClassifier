# MeTooClassifier

In this project, we are going to try to build a classifer that can categorize comments from Twitter posts that can be classified as triggering or sometimes just hateful.

A model like this can help automate targeted language that can do a few different things; it can help moderate a platform (particular with short form). It does become tricky as there are generational rubrick that would deem something that might be triggering or not. So a way one might be able to self moderate based on preference.

This could be something like a a NSFW filter where insensitive pictures are blurred out but is controlled by the user. This project is a start in building a mechanism that can be placed into the pipeline of a social media company to help provide this context.
